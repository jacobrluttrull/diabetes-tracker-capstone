{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9346fb44",
   "metadata": {},
   "source": [
    "\n",
    "# Diabetes Risk Model — Clean, Progressive Notebook\n",
    "\n",
    "This notebook is a **cleaned, step-by-step** version that rebuilds the final model from scratch with a clear flow:\n",
    "\n",
    "1. **Setup & Data Load**\n",
    "2. **Quick EDA**\n",
    "3. **Train/Test Split**\n",
    "4. **Preprocessing Pipeline**\n",
    "5. **Baseline Model (Logistic Regression)**\n",
    "6. **XGBoost (Core Model)**\n",
    "7. **Threshold Tuning (0.20 – 0.40 zoom)**\n",
    "8. **Final Evaluation at Chosen Threshold (0.301)**\n",
    "9. **Save Pipeline for GUI**\n",
    "10. **Example Inference**\n",
    "\n",
    "> Tip: Run the cells top-to-bottom. Where training could take longer, it's labeled.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca6c825",
   "metadata": {},
   "source": [
    "## 1) Setup & Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fb8c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Adjust the path below if needed.\n",
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = \"../data/diabetes_prediction_dataset.csv\"  # <- update if your path differs\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aef2ac8",
   "metadata": {},
   "source": [
    "## 2) Quick EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba43980",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Basic info\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f6035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Class balance\n",
    "df['diabetes'].value_counts(normalize=True).rename({0:'No',1:'Yes'}) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4623a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Summary stats of numerics\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b61f6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simple histograms for numeric features (matplotlib only)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "numeric_cols = ['age','bmi','HbA1c_level','blood_glucose_level']\n",
    "for col in numeric_cols:\n",
    "    plt.figure(figsize=(5,3))\n",
    "    df[col].hist(bins=30)\n",
    "    plt.title(f\"Distribution: {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3ddc99",
   "metadata": {},
   "source": [
    "## 3) Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ddd2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "FEATURES = ['age','hypertension','heart_disease','bmi','HbA1c_level','blood_glucose_level','gender','smoking_history']\n",
    "TARGET = 'diabetes'\n",
    "\n",
    "X = df[FEATURES].copy()\n",
    "y = df[TARGET].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4ace76",
   "metadata": {},
   "source": [
    "## 4) Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81983148",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "numeric_features = ['age','bmi','HbA1c_level','blood_glucose_level']\n",
    "categorical_features = ['gender','smoking_history']\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', StandardScaler(), numeric_features),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "])\n",
    "preprocessor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b51937",
   "metadata": {},
   "source": [
    "## 5) Baseline Model (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dcade5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "logreg_pipe = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "logreg_pipe.fit(X_train, y_train)\n",
    "y_pred_lr = logreg_pipe.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_lr))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_lr, digits=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d50f89f",
   "metadata": {},
   "source": [
    "## 6) XGBoost (Core Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72800be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# NOTE: This uses default-ish params; you can paste in your tuned params if you prefer.\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_pipe = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', XGBClassifier(\n",
    "        eval_metric='logloss',\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "xgb_pipe.fit(X_train, y_train)\n",
    "# Probability for class 1\n",
    "y_proba_xgb = xgb_pipe.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Default 0.5 threshold prediction for reference\n",
    "import numpy as np\n",
    "y_pred_xgb_default = (y_proba_xgb >= 0.5).astype(int)\n",
    "\n",
    "print(\"Accuracy (thr=0.5):\", accuracy_score(y_test, y_pred_xgb_default))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_xgb_default))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_xgb_default, digits=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d460ea66",
   "metadata": {},
   "source": [
    "## 7) Threshold Tuning (zoom 0.20–0.40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006d28bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "thresholds = np.arange(0.20, 0.401, 0.01)\n",
    "prec, rec, f1s = [], [], []\n",
    "\n",
    "for t in thresholds:\n",
    "    preds = (y_proba_xgb >= t).astype(int)\n",
    "    prec.append(precision_score(y_test, preds))\n",
    "    rec.append(recall_score(y_test, preds))\n",
    "    f1s.append(f1_score(y_test, preds))\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(thresholds, prec, label='Precision')\n",
    "plt.plot(thresholds, rec, label='Recall')\n",
    "plt.plot(thresholds, f1s, label='F1')\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Threshold vs Precision/Recall/F1 (XGBoost)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Choose your tuned threshold here (update if desired)\n",
    "TUNED_THRESHOLD = 0.301\n",
    "TUNED_THRESHOLD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e87230",
   "metadata": {},
   "source": [
    "## 8) Final Evaluation @ Tuned Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf029a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "y_pred_xgb_tuned = (y_proba_xgb >= TUNED_THRESHOLD).astype(int)\n",
    "\n",
    "print(f\"Accuracy (thr={TUNED_THRESHOLD}):\", accuracy_score(y_test, y_pred_xgb_tuned))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_xgb_tuned))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_xgb_tuned, digits=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddc9f3e",
   "metadata": {},
   "source": [
    "## 9) Save Pipeline for GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271e4dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import joblib\n",
    "\n",
    "OUTPUT_MODEL_PATH = \"../models/diabetes_pipeline.pkl\"  # adjust if needed\n",
    "joblib.dump(xgb_pipe, OUTPUT_MODEL_PATH)\n",
    "\n",
    "print(\"Saved pipeline to:\", OUTPUT_MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7180dc3",
   "metadata": {},
   "source": [
    "## 10) Example Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74d5891",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Provide a realistic example (adjust values as you like)\n",
    "example = pd.DataFrame([{\n",
    "    'age': 52,\n",
    "    'hypertension': 0,\n",
    "    'heart_disease': 0,\n",
    "    'bmi': 28.7,\n",
    "    'HbA1c_level': 6.1,\n",
    "    'blood_glucose_level': 145,\n",
    "    'gender': \"Male\",\n",
    "    'smoking_history': \"never\"\n",
    "}])\n",
    "\n",
    "proba = xgb_pipe.predict_proba(example)[0,1]\n",
    "pred = int(proba >= TUNED_THRESHOLD)\n",
    "\n",
    "print(f\"Probability: {proba:.3f}\")\n",
    "print(\"Prediction:\", \"Diabetic\" if pred==1 else \"Not Diabetic\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}